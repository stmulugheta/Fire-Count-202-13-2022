# -*- coding: utf-8 -*-
"""Farida_Final_OpenCV_easyOCRV2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VtKm7OUkv8f7SdJyy752mFiWXtcDubml

### Mount Drive
"""

from google.colab import drive
drive.mount("/content/drive")

!ls



"""### Install Packagaes"""

#!sudo apt install easyocr --quiet
!pip install pdf2image --quiet
!apt-get install poppler-utils --quiet

!pip install easyocr --quiet
import easyocr
import cv2
from pdf2image import convert_from_path
import tempfile
import os
import glob
from os import listdir
from PIL import Image
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
from google.colab.patches import cv2_imshow
pd.set_option('display.max_colwidth', None)
pd.set_option('display.max_rows', None)

"""### Modified PDf from 500 dataset: 5f4212d7-7bb7-45e5-9d74-3c1e26770e55.pdf

Trimmed the main Sustainabilty pages: 20 pages

"""

sample_pdf = "/content/drive/MyDrive/SustainLab/Modified_5f4212d7-7bb7-45e5-9d74-3c1e26770e55.pdf"

"""### Loading easyOCr english module"""

reader = easyocr.Reader(['en'])

"""### OpenCV SOP for creating bounding boxes:

- Main Goal: Find the Structure of the document. (Column-wise bounding boxes)

- Idea : Blur the image (adding noise) to help Open CV identify the structure.

### Procedure to Blur: These are standard SOPs(Standard Operating Procedure)

1. Change color of image to gray
2. Blur the image
3. Apply Thresh : Background is black and foreground is white
4. Kernal : Pre-requisite for 'dilate'
5. Dilate : Make text unreadable so that only paragraphs structure remain visible

### Function for SOPs (identifying structure of the document using OpenCV)
"""

def manipulate_img(rd_img):
  # convert colored image to gray and save it 'temp' folder
  gray = cv2.cvtColor(rd_img,cv2.COLOR_BGR2GRAY)
  cv2.imwrite("/content/drive/MyDrive/SustainLab/temp/Pages4_gray.png",gray)
  # Apply Gaussian Blur
  blur=cv2.GaussianBlur(gray,(7,7),0)
  cv2.imwrite("/content/drive/MyDrive/SustainLab/temp/Pages4_blur.png",blur)
  # Apply Thresh
  thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
  cv2.imwrite("/content/drive/MyDrive/SustainLab/temp/Pages4_THRESH.png",thresh)
  # Apply Kernal
  kernal =cv2.getStructuringElement(cv2.MORPH_RECT,(3,13))
  cv2.imwrite("/content/drive/MyDrive/SustainLab/temp/Pages4_kernal.png",kernal)
  # Apply Dilate
  dilate = cv2.dilate(thresh,kernal,iterations=2)
  cv2.imwrite("/content/drive/MyDrive/SustainLab/temp/Pages4_dilate.png",dilate)
  #cnts.append(conturs)
  
  return(dilate)

"""### Function to draw Bounding Boxes on the images"""

crop_img=[]
def bbox(contours_array,orig_img):
  i=0
  for c in contours_array:
    x,y,w,h = cv2.boundingRect(c)
    
    # Save bounding boxes only if the height is >200 and width >20
    if h > 200 and w > 20:
      roi= orig_img[y:y+h,x:x+h]
      #cv2.rectangle(read_img,(x,y),(x+w, y+h),(36,255,12),2)
      draw_bbox= cv2.rectangle(orig_img,(x,y),(x+w, y+h),(0,255,0),2)

      #crop image
      cropped_image = orig_img[y:y+h, x:x+w]
      crop_img.append(cropped_image)
      #plt.imshow(cropped_image)

      i += 1 

  return (draw_bbox)

read_img=[]
cnts=[]
image_path= r'/content/drive/MyDrive/SustainLab'
images = convert_from_path(sample_pdf)
for i in range(len(images)):
  images[i].save('/content/drive/MyDrive/SustainLab/Pages'+ str(i) +'.jpg', 'JPEG')
  read_img_temp = cv2.imread('/content/drive/MyDrive/SustainLab/Pages'+str(i) +'.jpg')
  read_img.append(read_img_temp)
  dialate_raw=manipulate_img(read_img_temp)
  conturs=cv2.findContours(dialate_raw,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
  conturs=conturs[0] if len(conturs) == 2 else conturs[1]
  conturs = sorted(conturs, key = cv2.contourArea, reverse = True)
  cnts.append(conturs)
  final_bbox=bbox(conturs,read_img_temp)
  bbox_sample=cv2.imwrite("/content/drive/MyDrive/SustainLab/temp/Pages_bbox" +str(i) +".jpg",final_bbox)

len(read_img)

#plt.imshow(read_img[2])
cv2_imshow(read_img[2])

len(crop_img)

#plt.imshow(crop_img[4])
cv2_imshow(crop_img[4])

"""### OCR each of the cropped image

- Done using EasyOcr
"""

text=''
for i in range (len(crop_img)):
  detection = reader.readtext(crop_img[i],decoder='beamsearch')
  #ocr_text(detection)
  for j in range(len(detection)):
    text = text + detection[j][1] +'\n'

"""### Ocr'd raw text saved in a "str" variable"""

print(text)
type(text)

"""### Save the raw extracted text in a .txt file"""

text_file = open("/content/drive/MyDrive/SustainLab/Output/All_Pages_Raw_Extract.txt", "w")
n = text_file.write(text)
text_file.close()

"""### Use regex to combine all sentences in 1 single line"""

with open('/content/drive/MyDrive/SustainLab/Output/All_Pages_Raw_Extract.txt') as f:

    exampleText = f.read()

new = ''

for line in exampleText.split('\n'):
    if line == '':
        new += '\n\n'
    elif re.search('[a-zA-Z]', line):  # check if there is text
        new += line + ' ' 
    else:
        new += line + '\n'

print(new)
type(new)

"""### Use regex patten Matching and Substitution

- Pattern matching for '.' and ':'

- ":" because Easyocr is replacing "." with ":" while OCR'ing - That is comimg from the algorithm.
"""

regex = r"(?<=\.|\?|\:|\_)\s"
test_str = new
subst = "\\n"
result = re.sub(regex, subst, test_str, 0, re.MULTILINE)
if result:
  print (result)

type(result)

"""### Save the Extracted sentences in a .txt file

- because the text is now character based because of regex usage
"""

text_file = open("/content/drive/MyDrive/SustainLab/Output/Final_Extracted_AllPages.txt", "w")
n = text_file.write(result)
text_file.close()

"""### Create dataframe to pull all text into CSV"""

df2 = pd.DataFrame(columns=["Sent_extracted"])
df2

final_extract = open('/content/drive/MyDrive/SustainLab/Output/Final_Extracted_AllPages.txt', 'r')

Lines = final_extract.readlines()

count=0
for line in Lines:
  count += 1
  df2 = df2.append({"Sent_extracted": line.strip()}, ignore_index=True)

"""### Save Extracted text in CSV file"""

df2.to_csv("/content/drive/MyDrive/SustainLab/Output/Final_Extracted_text_AllPages_5f4212d7-7bb7-45e5-9d74-3c1e26770e55.csv",index=False)

df2



