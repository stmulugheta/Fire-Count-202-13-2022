{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6936b1a2-962b-4fb5-8bb3-60752819419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910ce066-0ab1-44ca-a1c9-8851cb2ed0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncode:\n",
    "    \n",
    "    def __init__(self, model_name : str, max_length = 128, num_layers = 4):\n",
    "        self.config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name, config = self.config)\n",
    "        self.model.eval()\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __initTokens__(self, sentences):\n",
    "        self.tokens = {'input_ids': [], 'attention_mask': []}\n",
    "        for sentence in sentences:\n",
    "            new_tokens = self.tokenizer.encode_plus(sentence, max_length = self.max_length,\n",
    "                                               truncation=True, padding='max_length',\n",
    "                                               return_tensors='pt')\n",
    "            self.tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "            self.tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "        # reformat list of tensors into single tensor\n",
    "        self.tokens['input_ids'] = torch.stack(self.tokens['input_ids'])\n",
    "        self.tokens['attention_mask'] = torch.stack(self.tokens['attention_mask'])\n",
    "        \n",
    "    def __getDenseVectors__(self, aggr_last_layers : torch.Tensor) -> np.ndarray:\n",
    "        attention_mask = self.tokens['attention_mask']\n",
    "        mask = attention_mask.unsqueeze(-1).expand(aggr_last_layers.size()).float()\n",
    "        masked_embeddings = aggr_last_layers * mask\n",
    "        aggr = torch.sum(masked_embeddings, 1)\n",
    "        aggr_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "        mean_pooled = aggr / aggr_mask\n",
    "        mean_pooled = mean_pooled.detach().numpy()\n",
    "        return mean_pooled\n",
    "        \n",
    "    def __getOutputs__(self, sentences) -> torch.Tensor:\n",
    "        self.__initTokens__(sentences)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**self.tokens)\n",
    "            aggr_last_layers = torch.stack(outputs.hidden_states[-self.num_layers:]).sum(0)\n",
    "            return aggr_last_layers\n",
    "        \n",
    "    def get_sentence_embeddings(self, sentences):\n",
    "        aggr_last_layers = self.__getOutputs__(sentences)\n",
    "        dense_vectors = self.__getDenseVectors__(aggr_last_layers)\n",
    "        return dense_vectors\n",
    "    \n",
    "    def get_similarity_matrix(self, sentences_1, sentences_2):\n",
    "        return cosine_similarity(\n",
    "            self.get_sentence_embeddings(sentences_1),\n",
    "            self.get_sentence_embeddings(sentences_2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46852ef4-2d05-4cc5-a915-7e679afb5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"../Data/input_datasets/fb62e200-0fa3-11ec-82a8-0242ac130003/fb62e200-0fa3-11ec-82a8-0242ac130003_topics.csv\")\n",
    "data_df = data_df[data_df['Topics'].notna()].iloc[:100]\n",
    "kpi_df = pd.read_csv(\"../Data/kpi_lists/GRI KPI list.csv\")\n",
    "kpi_df[\"Description of KPI\"] = kpi_df[\"Description of KPI\"].fillna(method = \"ffill\")\n",
    "kpi_df[\"Descriptive KPI\"] = kpi_df[\"Description of KPI\"] + \". \" + kpi_df[\"KPI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a24054-7e49-4760-8297-0d28448a820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nbroad/ESG-BERT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b070cf-5269-4dbd-97c6-c348ca24cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_kpi(model_class):\n",
    "    sim_matrix = model_class.get_similarity_matrix(data_df[\"sentences\"], kpi_df[\"Descriptive KPI\"])\n",
    "    sim_index = [sim.argmax() for sim in sim_matrix]\n",
    "    sim_score = [sim.max() for sim in sim_matrix]\n",
    "    df = pd.DataFrame()\n",
    "    df[\"sentences\"] = list(data_df[\"sentences\"])\n",
    "    df[\"KPI\"] = list(kpi_df[\"KPI\"].iloc[sim_index])\n",
    "    df[\"score\"] = list(sim_score)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c702f4-727d-4d92-a12d-b5da57f9de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nbroad/ESG-BERT were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "sim = BertEncode(model_name, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1883fb5-a176-4349-90e0-0cfa9343b7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>KPI</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>putting the growth of nations back on track will require a sustained effort over time, and also ...</td>\n",
       "      <td>total number of critical concerns communicated to highest governance body</td>\n",
       "      <td>0.455011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>during these months in which our attention has been focussed on peoples health, the challenges o...</td>\n",
       "      <td>total number of critical concerns communicated to highest governance body</td>\n",
       "      <td>0.511303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this figure supposes more than 80 times the_emissions we needed to produce and purify more than ...</td>\n",
       "      <td>persistent organic pollutants</td>\n",
       "      <td>0.527940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in 2020, more than eight out of every ten euros invested by acciona businesses financed projects...</td>\n",
       "      <td>co2 equivalent of GHG emissions reduced</td>\n",
       "      <td>0.903068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>technologies integrated in acciona projects that have allowed us to increase our positive impact...</td>\n",
       "      <td>total cooling energy sold</td>\n",
       "      <td>0.561492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             sentences  \\\n",
       "0  putting the growth of nations back on track will require a sustained effort over time, and also ...   \n",
       "1  during these months in which our attention has been focussed on peoples health, the challenges o...   \n",
       "2  this figure supposes more than 80 times the_emissions we needed to produce and purify more than ...   \n",
       "3  in 2020, more than eight out of every ten euros invested by acciona businesses financed projects...   \n",
       "4  technologies integrated in acciona projects that have allowed us to increase our positive impact...   \n",
       "\n",
       "                                                                         KPI  \\\n",
       "0  total number of critical concerns communicated to highest governance body   \n",
       "1  total number of critical concerns communicated to highest governance body   \n",
       "2                                             persistent organic pollutants    \n",
       "3                                    co2 equivalent of GHG emissions reduced   \n",
       "4                                                  total cooling energy sold   \n",
       "\n",
       "      score  \n",
       "0  0.455011  \n",
       "1  0.511303  \n",
       "2  0.527940  \n",
       "3  0.903068  \n",
       "4  0.561492  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esg_bert_df = get_sentences_kpi(sim)\n",
    "esg_bert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771ad17-d41d-4070-aa48-5b64186d19f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
